{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text\n",
       "0      1  Total bill for this horrible service? Over $8G...\n",
       "1      5  I *adore* Travis at the Hard Rock's new Kelly ...\n",
       "2      5  I have to say that this office really has it t...\n",
       "3      5  Went in for a lunch. Steak sandwich was delici...\n",
       "4      1  Today was my second out of three sessions I ha..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "def load_data():\n",
    "    data = []\n",
    "    data_labels = []\n",
    "    \n",
    "csv_reader = pd.read_csv('K.csv')\n",
    "        #with open(\"C:\\\\Users\\\\LENOVO\\\\Desktop\\\\CMPE-255-Assignments\\\\Assignment-1\\\\Reviews.csv\", \"rb\") as csv_file:\n",
    "        #csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "csv_reader.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "pos = [ \"good\", \"creamy\", \"delicious\", \"like\", \"liked\", \"persistent\", \"care\", \"cared\", \"clean\", \"neat\", \"warm\", \"loved\", \"comfortable\", \"trust\", \"recommend\", \"best\", \"amazing\", \"adore\", \"fan\", \"great\", \"flawless\",\"organized\", \"friendly\", \"professional\", \"help\", \"helped\", \"perfect\", \"excited\", \"favorite\", \"tender\", \"right\", \"overwhelmed\", \"smooth\", \"easy\", \"high \", \"high quality\", \"reasonable\", \"knowledgeable\", \"enjoy\", \"enjoyed\", \"fun\", \"fresh\", \"tasty\", \"yummy\", \n",
    "       \"healthy\", \"excellent\", \"pleased\", \"pleasing\", \"pleasure\", \"kind\", \"delightful\", \"fantastic\", \"efficient\", \"smokey\", \"juicy\", \"nice\", \"nicely\", \"hot\", \"toasted\", \"crispy\", \"heat\", \" big\", \"personalized\", \"enjoying\", \"equipped\", \"latest\", \"glad\", \"phenomenal\" ]\n",
    "\n",
    "neg = [ \"old\", \"horrible\", \"crooks\", \"avoid\", \"down hill\", \"cut back\", \"big deal\", \"sick\", \"disappoint\", \"disappointed\", \"bad\", \"bitter\", \"worst\", \"wrong\", \"limited\", \"unprofessional\", \"rude\", \"rudely\", \"empty\", \"low\", \"cold\", \"discriminate\", \"discrimination\", \"sad\", \"sadly\", \"busy\", \"problem\", \"second thoughts\", \"dreadful\", \"awful\", \"terrible\", \"crappy\", \"crappier\" ]\n",
    "\n",
    "negations = [ \"not\" , \"no\" , \"did not\", \"didn't\" , \"cannot\" , \"can't\" , \"never\" ,\"isn't\" , \"wasn't\" ,\"pleased\", \"pleasing\", \"pleasure\", \"kind\", \"delightful\", \"fantastic\"]\n",
    "\n",
    "comments = []\n",
    "labels = []\n",
    "with open('K.csv', newline='', encoding=\"utf8\") as csvfile:\n",
    "    csv_file = csv.reader(csvfile, delimiter=',')\n",
    "    line = 0\n",
    "    for row in csv_file:\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        if line > 0:\n",
    "            comments.append(row[1]);\n",
    "            for p in pos:\n",
    "                if p in row[1]:\n",
    "                    positive += 1\n",
    "            for n in neg:\n",
    "                if n in row[1]:\n",
    "                    negative += 1\n",
    "            for p in pos:\n",
    "                for n in negations:\n",
    "                    st1 = p + n\n",
    "                    st2 = n + p\n",
    "                    if st1 in row[1]:\n",
    "                        negative += 1\n",
    "                    if st2 in row[1]:\n",
    "                        negative += 1\n",
    "            for n in neg:\n",
    "                for p in negations:\n",
    "                    st1 = p + n\n",
    "                    st2 = n + p\n",
    "                    if st1 in row[1]:\n",
    "                        positive += 1\n",
    "                    if st2 in row[1]:\n",
    "                        positive += 1\n",
    "            if positive > negative:\n",
    "                labels.append('pos')\n",
    "            elif (positive < negative):\n",
    "                labels.append('neg')\n",
    "            else:\n",
    "                labels.append('neut')\n",
    "\n",
    "\n",
    "        line += 1\n",
    "    \n",
    "\n",
    "print(positive)\n",
    "print(negative)\n",
    "print(len(labels))\n",
    "print(len(comments))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-976cfc4949d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mfeatures_nd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_to_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mtrain_then_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_nd\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-82-976cfc4949d3>\u001b[0m in \u001b[0;36mtrain_then_build_model\u001b[1;34m(data_labels, features_nd)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mlog_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mlog_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1285\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m--> 501\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def transform_to_features(data):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    vectorizer = CountVectorizer(\n",
    "        analyzer = 'word',\n",
    "        lowercase = False,\n",
    "    )\n",
    "    features = vectorizer.fit_transform(\n",
    "        data\n",
    "    )\n",
    "    features_nd = features.toarray()\n",
    "    return features_nd\n",
    "\n",
    "def train_then_build_model(data_labels, features_nd):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    # TODO : set training % to 80%.\n",
    "    X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_nd, \n",
    "        data_labels,\n",
    "        train_size=0.80, \n",
    "        random_state=0)\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    log_model = LogisticRegression()\n",
    "\n",
    "    log_model = log_model.fit(X=X_train, y=y_train)\n",
    "    y_pred = log_model.predict(X_test)\n",
    "\n",
    "     # ::{prediction}::{tweet}\n",
    "    \n",
    "    # print accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    # TODO\n",
    "    print()\n",
    "    print(\"Accuracy=\",accuracy_score(y_test, y_pred))\n",
    "\n",
    "features_nd = transform_to_features(comments)\n",
    "train_then_build_model(labels, features_nd )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
